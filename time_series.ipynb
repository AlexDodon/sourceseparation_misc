{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes sure to reload our modules on each execution\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 1\n",
    "%aimport gans, preprocessing, sourceSeparation, thresholding, testingPipeline\n",
    "\n",
    "import concurrent.futures\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data init\n",
    "\n",
    "# dataset\n",
    "baseDatasetPath = \"../data/datasets\"\n",
    "inclusionThreshold = 0.5\n",
    "includedSims = 24\n",
    "\n",
    "# iters to run\n",
    "iters = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "snrs=range(1,7)\n",
    "\n",
    "#SDs to test\n",
    "sdMuls = list(range(1, 6))\n",
    "\n",
    "# gans\n",
    "batchSize = 64\n",
    "baseModelPath = \"../data/models\"\n",
    "epochs = 5\n",
    "noiseDim = 200\n",
    "\n",
    "#results\n",
    "resultsPath = \"../data/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "array = np.array([[3,  20],\n",
    "                      [ 15, 100]])\n",
    "\n",
    "classes = [\"Class A\", \"Class B\"]\n",
    "\n",
    "#df_cm = pd.DataFrame(array, index=classes, columns=classes)\n",
    "# plt.figure(figsize=(10,7))\n",
    "#sn.set(font_scale=1.4) # for label size\n",
    "#sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "\n",
    "#plt.show()\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax1 = plt.subplot2grid((3,3), (0,0), colspan=2, rowspan=2)\n",
    "ax2 = plt.subplot2grid((3,3), (2,0), colspan=2, rowspan=1)\n",
    "ax3 = plt.subplot2grid((3,3), (0,2), colspan=1, rowspan=2)\n",
    "sn.color_palette(\"Paired\")\n",
    "pv = pd.DataFrame(array, index=classes, columns=classes)\n",
    "\n",
    "c = sn.color_palette(\"light:b\", as_cmap=True)\n",
    "\n",
    "sn.heatmap(pv, ax=ax1,cmap=c, annot=True, linecolor='b', cbar = False,fmt='d',center=np.mean(pv)[0])\n",
    "ax1.xaxis.tick_top()\n",
    "ax1.set_xticklabels(classes,rotation=40)\n",
    "ax1.set_yticklabels(classes,rotation=40)\n",
    "\n",
    "sn.heatmap((pd.DataFrame(np.sum(pv,axis=0))).transpose(), ax=ax2,cmap=c,  annot=True, cbar=False, xticklabels=False, yticklabels=False,fmt='d',center=np.mean(pv,axis=0)[0])\n",
    "sn.heatmap(pd.DataFrame(np.sum(pv,axis=1)), ax=ax3,  annot=True,cmap=c, cbar=False, xticklabels=False, yticklabels=False,fmt='d',center=np.mean(pv,axis=1)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "snr = 6\n",
    "\n",
    "genSpike = gans.GeneratorWgan(inputSize=noiseDim, hiddenSize=80, outputSize=80)\n",
    "criticSpike = gans.CriticWgan(inputSize=80, hiddenSize=40)\n",
    "genSpike.load_state_dict(torch.load(f\"{baseModelPath}/it-{i}-gen-spike.pth\"))\n",
    "genSpike.to(gans.device)\n",
    "criticSpike.load_state_dict(torch.load(f\"{baseModelPath}/it-{i}-critic-spike.pth\"))\n",
    "criticSpike.to(gans.device)\n",
    "\n",
    "genNoise = gans.GeneratorWgan(inputSize=noiseDim, hiddenSize=80, outputSize=80)\n",
    "criticNoise = gans.CriticWgan(inputSize=80, hiddenSize=40)\n",
    "genNoise.load_state_dict(torch.load(f\"{baseModelPath}/it-{i}-gen-noise.pth\"))\n",
    "genNoise.to(gans.device)\n",
    "criticNoise.load_state_dict(torch.load(f\"{baseModelPath}/it-{i}-critic-noise.pth\"))\n",
    "criticNoise.to(gans.device)\n",
    "\n",
    "# separating noise as it is the same for all snrs\n",
    "print(f\"\\nSeparating dataset with snr {snr}\\n\")\n",
    "\n",
    "\n",
    "print(\"Separating validation spikes\")\n",
    "\n",
    "errs = np.zeros((9,5))\n",
    "eps = [1, 100, 300, 600, 1000, 2000, 3000, 4000, 5000]\n",
    "for it in range(5):\n",
    "    print(f\"{it} iterations\")\n",
    "    valBgLoader = pickle.load(open(f\"{baseDatasetPath}/it-{it}-non-drowned-valBgLoader.pickle\", \"rb\"))\n",
    "    testBgLoader = pickle.load(open(f\"{baseDatasetPath}/it-{it}-non-drowned-testBgLoader.pickle\", \"rb\"))\n",
    "    valSpikesLoader = pickle.load(open(f\"{baseDatasetPath}/it-{it}-snr-{snr}-valSpikesLoader.pickle\", \"rb\"))\n",
    "\n",
    "    for ep in eps:\n",
    "        print(f\"{ep} epochs\")\n",
    "        (cleanextractedSpikesValidationSpikes,cleanextractedNoisesValidationSpikes, err) = sourceSeparation.maxlikelihood_separatesources(\n",
    "            generators=[genSpike, genNoise],\n",
    "            discriminators=[criticSpike, criticNoise],\n",
    "            loader_mix=valSpikesLoader,\n",
    "            epochs=ep,\n",
    "            doPrint=True\n",
    "        )\n",
    "\n",
    "        errs[eps.index(ep)][it] = (err)\n",
    "        print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "batchSize = 64\n",
    "noiseDim = 200\n",
    "includedSimulations=24\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generates preprocessed datasets for our models and saves them to disk\n",
    "snr = 1\n",
    "toSave = \"1.0\"\n",
    "\n",
    "trainSpikesLoader, valSpikesLoader, testSpikesLoader, trainBgLoader, valBgLoader, testBgLoader = preprocessing.gen_loaders( \n",
    "    batchSize,\n",
    "    1,\n",
    "    doDrown=False,\n",
    "    snr=snr,\n",
    "    inclusionThreshold=0.5\n",
    ")\n",
    "\n",
    "pickle.dump(trainSpikesLoader, open(f\"../data/datasets/trainSpikesLoader{toSave}.pickle\", \"wb\"))\n",
    "pickle.dump(valSpikesLoader, open(f\"../data/datasets/valSpikesLoader{toSave}.pickle\", \"wb\"))\n",
    "pickle.dump(testSpikesLoader, open(f\"../data/datasets/testSpikesLoader{toSave}.pickle\", \"wb\"))\n",
    "pickle.dump(trainBgLoader, open(f\"../data/datasets/trainBgLoader{toSave}.pickle\", \"wb\"))\n",
    "pickle.dump(valBgLoader, open(f\"../data/datasets/valBgLoader{toSave}.pickle\", \"wb\"))\n",
    "pickle.dump(testBgLoader, open(f\"../data/datasets/testBgLoader{toSave}.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainSpikesLoader.dataset[:][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads preprocessed datasets from disk\n",
    "toLoad1 = \"orig\"\n",
    "toLoad2 = \".snr.1.0\"\n",
    "\n",
    "trainSpikesLoader = pickle.load(open(f\"../data/datasets/trainSpikesLoader{toLoad1}.pickle\", \"rb\"))\n",
    "valSpikesLoader = pickle.load(open(f\"../data/datasets/valSpikesLoader{toLoad2}.pickle\", \"rb\"))\n",
    "testSpikesLoader = pickle.load(open(f\"../data/datasets/testSpikesLoader{toLoad2}.pickle\", \"rb\"))\n",
    "trainBgLoader = pickle.load(open(f\"../data/datasets/trainBgLoader{toLoad1}.pickle\", \"rb\"))\n",
    "valBgLoader = pickle.load(open(f\"../data/datasets/valBgLoader{toLoad2}.pickle\", \"rb\"))\n",
    "testBgLoader = pickle.load(open(f\"../data/datasets/testBgLoader{toLoad2}.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = testingPipeline.testThresholding(1, 5, trainSpikesLoader, valSpikesLoader, testSpikesLoader, trainBgLoader, valBgLoader, testBgLoader)\n",
    "\n",
    "for x in res:\n",
    "    print(f\"{x} * sd\")\n",
    "    \n",
    "    [labels, pred] = res[x]\n",
    "    \n",
    "    confusionMatrix = testingPipeline.confusionMatrix(labels,pred)\n",
    "    print(confusionMatrix)\n",
    "\n",
    "    accuracy, sensitivity, specificity = testingPipeline.metrics(confusionMatrix)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Sensitivity: {sensitivity}\")\n",
    "    print(f\"Specificity: {specificity}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, sd = thresholding.computeThreshold(trainSpikesLoader, valSpikesLoader, testSpikesLoader, trainBgLoader, valBgLoader, testBgLoader)\n",
    "\n",
    "pred = thresholding.thresholdDatasets(mean, 3 * sd, testSpikesLoader, testBgLoader)\n",
    "\n",
    "labels = np.concatenate(([1 for _ in range(0,len(testSpikesLoader.dataset))],[0 for _ in range(0,len(testBgLoader.dataset))]),axis=0)\n",
    "\n",
    "confusionMatrix = testingPipeline.confusionMatrix(labels,pred)\n",
    "print(confusionMatrix)\n",
    "\n",
    "accuracy, sensitivity, specificity = testingPipeline.metrics(confusionMatrix)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# declares and trains the gan for spikes \n",
    "\n",
    "gen1 = gans.GeneratorWgan(inputSize=noiseDim, hiddenSize=80, outputSize=80)\n",
    "critic1 = gans.CriticWgan(inputSize=80, hiddenSize=40)\n",
    "\n",
    "print(\"Spike generator training\")\n",
    "\n",
    "gans.wgan_adversarial_trainer( \n",
    "    train_loader = trainSpikesLoader,\n",
    "    generator = gen1, \n",
    "    critic = critic1, \n",
    "    batchSize = batchSize,\n",
    "    noiseDim = noiseDim,\n",
    "    epochs = 5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# declares and trains the gan for hash\n",
    "\n",
    "gen2 = gans.GeneratorWgan(inputSize=noiseDim, hiddenSize=10, outputSize=80)\n",
    "critic2 = gans.CriticWgan(inputSize=80, hiddenSize=40)\n",
    "print(\"Background generator training\")\n",
    "\n",
    "gans.wgan_adversarial_trainer( \n",
    "    train_loader = trainBgLoader,\n",
    "    generator = gen2, \n",
    "    critic = critic2, \n",
    "    batchSize = batchSize,\n",
    "    noiseDim = noiseDim,\n",
    "    epochs = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(gen1.state_dict(),\"../data/models/gen1.orig.pth\")\n",
    "torch.save(critic1.state_dict(),\"../data/models/critic1.orig.pth\")\n",
    "torch.save(gen2.state_dict(),\"../data/models/gen2.orig.pth\")\n",
    "torch.save(critic2.state_dict(),\"../data/models/critic2.orig.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toLoad1 = \"orig\"\n",
    "gen1 = gans.GeneratorWgan(inputSize=noiseDim, hiddenSize=80, outputSize=80)\n",
    "critic1 = gans.CriticWgan(inputSize=80, hiddenSize=40)\n",
    "gen1.load_state_dict(torch.load(f\"../data/models/gen1.{toLoad1}.pth\"))\n",
    "gen1.to(gans.device)\n",
    "critic1.load_state_dict(torch.load(f\"../data/models/critic1.{toLoad1}.pth\"))\n",
    "critic1.to(gans.device)\n",
    "\n",
    "gen2 = gans.GeneratorWgan(inputSize=noiseDim, hiddenSize=10, outputSize=80)\n",
    "critic2 = gans.CriticWgan(inputSize=80, hiddenSize=40)\n",
    "gen2.load_state_dict(torch.load(f\"../data/models/gen2.{toLoad1}.pth\"))\n",
    "gen2.to(gans.device)\n",
    "critic2.load_state_dict(torch.load(f\"../data/models/critic2.{toLoad1}.pth\"))\n",
    "critic2.to(gans.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "allPrecision = []\n",
    "allRecall = []\n",
    "allF1 = []\n",
    "allAccuracy = []\n",
    "allSpecificity = []\n",
    "\n",
    "for snr in [x/2 for x in range(12,0,-1)]:\n",
    "    toLoad2 = f\".snr.{snr}\"\n",
    "    \n",
    "    print(toLoad2)\n",
    "\n",
    "    valSpikesLoader = pickle.load(open(f\"../data/datasets/valSpikesLoader{toLoad2}.pickle\", \"rb\"))\n",
    "    testSpikesLoader = pickle.load(open(f\"../data/datasets/testSpikesLoader{toLoad2}.pickle\", \"rb\"))\n",
    "    valBgLoader = pickle.load(open(f\"../data/datasets/valBgLoader{toLoad2}.pickle\", \"rb\"))\n",
    "    testBgLoader = pickle.load(open(f\"../data/datasets/testBgLoader{toLoad2}.pickle\", \"rb\"))\n",
    "    \n",
    "    (cleanextractedSpikesValidationSpikes,cleanextractedNoisesValidationSpikes) = sourceSeparation.maxlikelihood_separatesources(\n",
    "        generators=[gen1, gen2],\n",
    "        loader_mix=valSpikesLoader,\n",
    "        epochs=3000\n",
    "    )\n",
    "    \n",
    "    (cleanextractedSpikesValidationBg,cleanextractedNoisesValidationBg) = sourceSeparation.maxlikelihood_separatesources(\n",
    "        generators=[gen1, gen2],\n",
    "        loader_mix=valBgLoader,\n",
    "        epochs=3000\n",
    "    )\n",
    "    \n",
    "    valExtractedSpikes = np.concatenate((cleanextractedSpikesValidationSpikes,cleanextractedSpikesValidationBg),axis=0)\n",
    "    vallabel = np.concatenate(([1 for _ in cleanextractedSpikesValidationSpikes],[0 for _ in cleanextractedSpikesValidationBg]),axis=0)\n",
    "    \n",
    "    valThreshold, _, _, _, _, _ = sourceSeparation.interpretSeparation(valExtractedSpikes, critic1, vallabel,method=\"energy\")\n",
    "    \n",
    "    (cleanextractedSpikesTestSpikes,cleanextractedNoisesTestSpikes) = sourceSeparation.maxlikelihood_separatesources(\n",
    "        generators=[gen1, gen2],\n",
    "        loader_mix=testSpikesLoader,\n",
    "        epochs=3000\n",
    "    )\n",
    "    \n",
    "    (cleanextractedSpikesTestBg,cleanextractedNoisesTestBg) = sourceSeparation.maxlikelihood_separatesources(\n",
    "        generators=[gen1, gen2],\n",
    "        loader_mix=testBgLoader,\n",
    "        epochs=3000\n",
    "    )\n",
    "    \n",
    "    testExtractedSpikes = np.concatenate((cleanextractedSpikesTestSpikes,cleanextractedSpikesTestBg),axis=0)\n",
    "    testlabel = np.concatenate(([1 for _ in cleanextractedSpikesTestSpikes],[0 for _ in cleanextractedSpikesTestBg]),axis=0)\n",
    "    \n",
    "    (_, precision, recall, spec, f1, acc) = sourceSeparation.interpretSeparation(testExtractedSpikes, critic1, testlabel,test=True, testThreshold=valThreshold,method=\"energy\")\n",
    "    \n",
    "    allPrecision.append(precision)\n",
    "    allRecall.append(recall)\n",
    "    allF1.append(f1)\n",
    "    allAccuracy.append(acc)\n",
    "    allSpecificity.append(spec)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy\")\n",
    "print(allAccuracy)\n",
    "print(\"Precision\")\n",
    "print(allPrecision)\n",
    "print(\"Recall\")\n",
    "print(allRecall)\n",
    "print(\"Specificity\")\n",
    "print(allSpecificity) \n",
    "print(\"F1\")\n",
    "print(allF1)\n",
    "print(\"snrs\")\n",
    "print([x/2 for x in range(12,0,-1)])\n",
    "plt.plot(allAccuracy)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "allAccuracy = [0.988293463244383, 0.9855789039967038, 0.9827431590683244, 0.9781623403378656, 0.9737027072881068, 0.965437843864369, 0.9527375845270123, 0.9335902469764172, 0.907680748442764, 0.8720036840446933, 0.8016190406941516, 0.6679754720182264]\n",
    "allPrecision = [0.9909826476896081, 0.9877300613496932, 0.983492741661407, 0.980842351564785, 0.9748299319727891, 0.9676586625103502, 0.953836435200933, 0.9416382758109909, 0.8994869846095382, 0.8688713708902134, 0.7805229936880073, 0.6198713069950875]\n",
    "allRecall = [0.985554316738572, 0.9833729216152018, 0.9819671336468079, 0.9753744728295118, 0.9725144214455378, 0.9630617092442678, 0.9515245528139997, 0.9244752532842115, 0.9179310679141015, 0.8762421833341413, 0.8392069416840371, 0.8685830626787532]\n",
    "allF1 = [0.9882610280714546, 0.9855466757354191, 0.9827293455586281, 0.9781007704834359, 0.9736708000679463, 0.965354713313897, 0.9526790914385557, 0.9329778386575999, 0.9086154362899163, 0.8725412111119156, 0.8088018874535731, 0.7234480670233168]\n",
    "accDict = {1: [0.6157444436365399, 0.61530817518602, 0.61509004096076, 0.6173198574856394, 0.6122542960323808, 0.6104365108218813, 0.6083763542499818, 0.603722824111103, 0.603795535519523, 0.5976393029399646, 0.5802612763275892, 0.5535761894374561], 2: [0.8998521534695461, 0.8953925204197872, 0.8865944400009694, 0.8777963595821517, 0.865411183014615, 0.8485906105334594, 0.8263651566930852, 0.7979592331370126, 0.7600281150779223, 0.7182675295087132, 0.6617465280302479, 0.592137473036186], 3: [0.8571947938631571, 0.8397440558423617, 0.8216631522819263, 0.7954870452507332, 0.773164642865799, 0.7449283792627063, 0.7130323081024746, 0.6810392883976829, 0.6453622239996122, 0.6141690297874404, 0.5778860369858697, 0.5414091470951793], 4: [0.7152378874912141, 0.695920889987639, 0.6801425143605032, 0.6586199374681888, 0.642259870573693, 0.6183620543396592, 0.5987784483385443, 0.5813277103177489, 0.5609200416878741, 0.5454325116944182, 0.5282241450350227, 0.5138515233040064], 5: [0.6145083496934002, 0.6010082648634237, 0.5890351196102669, 0.5742747037010106, 0.5682881310744322, 0.5524855183111563, 0.5422332097239391, 0.5344288518868611, 0.5251460287452434, 0.5163721854625657, 0.5101917157468674, 0.503938534622749]}\n",
    "precisionDict = {1: [0.5654593809119074, 0.5651768832378813, 0.5650517893352331, 0.5664725594682195, 0.5632805881227624, 0.5621453513749455, 0.5609643022716736, 0.5582700111664897, 0.5587186660084471, 0.5555249228054698, 0.5462184873949579, 0.5318058833688332], 2: [0.8563836681788723, 0.8554804968402702, 0.8498420775574662, 0.8470410117112704, 0.8432604735883424, 0.8360280373831775, 0.8269314815714077, 0.8160316725795671, 0.7963863410321582, 0.7730277120853799, 0.7362458401189549, 0.6662002623524268], 3: [0.9754791249919339, 0.9742201772785709, 0.972176759410802, 0.9688485501115299, 0.9647806004618937, 0.9597779597779598, 0.9510417735810326, 0.9422143280047365, 0.9290313349549292, 0.9175531914893617, 0.8838709677419355, 0.8234848484848485], 4: [0.9957570343903528, 0.9949785670545009, 0.9948069241011984, 0.991882140709561, 0.9926137317441666, 0.9887887887887888, 0.9894306990151334, 0.9838477069512547, 0.9783022459078797, 0.9756345177664975, 0.948382126348228, 0.9192364170337739], 5: [0.9993657505285413, 0.9995204986813714, 0.9991845610220168, 0.9990228013029316, 0.9989373007438895, 0.9990779160903642, 0.9971461187214612, 0.9978962131837307, 0.9933396764985728, 0.9927007299270073, 0.9883720930232558, 0.9821428571428571]}\n",
    "recallDict = {1: [0.99975762276407, 0.999806098211256, 0.999612196422512, 0.999709147316884, 0.999127441950652, 0.998885064714722, 0.997139948616026, 0.993649716418634, 0.987541810073198, 0.9767802607979058, 0.9484221241940957, 0.8956323622085414], 2: [0.9608318386737118, 0.9515245528139997, 0.9391148383343836, 0.9220999563720975, 0.8976683309903534, 0.8672742256047312, 0.825488390130399, 0.7693538222890106, 0.6986766202918222, 0.6179650007271317, 0.5040476998400311, 0.3692859566629502], 3: [0.7328033351107665, 0.6979494885840322, 0.6622715594551359, 0.6105967327548597, 0.5670173057346454, 0.511270541470745, 0.4491734936254787, 0.3857191332590043, 0.3147510785786999, 0.2508604391875515, 0.1793106791410151, 0.10538562218236464], 4: [0.4323040380047506, 0.3938145329390664, 0.36216006592660815, 0.31984100053322995, 0.2866353192108197, 0.23942023365165543, 0.1996703669591352, 0.165349750351447, 0.12458189926802075, 0.09316980949149256, 0.059673275485966355, 0.030345629938436182], 5: [0.22914343884822339, 0.2020941393184352, 0.17819574385573708, 0.1486741965194629, 0.1367007610645208, 0.10504629405206263, 0.0846866062339425, 0.06898056134567841, 0.050608366862184305, 0.0329633040864802, 0.020602065054050125, 0.007998448785690048]}\n",
    "f1Dict = {1: [0.7223564848866939, 0.7221385805819125, 0.7219858900968086, 0.7231699833435609, 0.7204124432016776, 0.7194204416513923, 0.7180006282941812, 0.7148885711296342, 0.7136676533954563, 0.7082476582133882, 0.693204365079365, 0.667352946488234], 2: [0.90560606752867, 0.9009501078624867, 0.8922510074841681, 0.882978229587337, 0.8696142196341777, 0.8513645340122297, 0.8262093057105429, 0.7920055891012526, 0.7443385751542851, 0.6868534482758621, 0.5984116022099448, 0.47517465069860276], 3: [0.8369041687427337, 0.8132625395390872, 0.7878438383022892, 0.7490930716622064, 0.7142551827313528, 0.6671516224935162, 0.6101672593177927, 0.5473619041067621, 0.4702005938156275, 0.39400053294758086, 0.29813814781977915, 0.18685805148480814], 4: [0.6028730775730945, 0.5642842258803917, 0.5310067877323288, 0.4837066089952715, 0.44482058226134047, 0.3854979706525133, 0.3322846079380445, 0.28311752988047806, 0.2210182318541452, 0.1700960219478738, 0.11228166187804987, 0.058751759737212576], 5: [0.37280649867897003, 0.3362096774193548, 0.3024518676978773, 0.2588294864762226, 0.24049121610097218, 0.19010439512237914, 0.15611456145837987, 0.1290410337791884, 0.09630996309963101, 0.06380782584216946, 0.04036279025594758, 0.01586767322209934]}\n",
    "multiplesOfSd = list(range(1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "multiplesOfSd = list(range(1,6))\n",
    "\n",
    "accDict = {}\n",
    "precisionDict = {}\n",
    "recallDict = {}\n",
    "specDict = {}\n",
    "f1Dict = {}\n",
    "\n",
    "for x in multiplesOfSd:\n",
    "    accDict[x] = []\n",
    "    precisionDict[x] = []\n",
    "    recallDict[x] = []\n",
    "    f1Dict[x] = []\n",
    "    specDict[x] = []\n",
    "    \n",
    "\n",
    "for snr in [x/2 for x in range(12,0,-1)]:\n",
    "    toLoad2 = f\".snr.{snr}\"\n",
    "    \n",
    "    print(toLoad2)\n",
    "    \n",
    "    valSpikesLoader = pickle.load(open(f\"../data/datasets/valSpikesLoader{toLoad2}.pickle\", \"rb\"))\n",
    "    testSpikesLoader = pickle.load(open(f\"../data/datasets/testSpikesLoader{toLoad2}.pickle\", \"rb\"))\n",
    "    valBgLoader = pickle.load(open(f\"../data/datasets/valBgLoader{toLoad2}.pickle\", \"rb\"))\n",
    "    testBgLoader = pickle.load(open(f\"../data/datasets/testBgLoader{toLoad2}.pickle\", \"rb\"))\n",
    "    \n",
    "    mean, sd = thresholding.computeThreshold(trainSpikesLoader, valSpikesLoader, testSpikesLoader, trainBgLoader, valBgLoader, testBgLoader)    \n",
    "\n",
    "    for sdMultiple in multiplesOfSd:\n",
    "\n",
    "        print(f\"{sdMultiple} * sd\")\n",
    "\n",
    "        testPredictions = thresholding.thresholdDatasets(mean, sd * sdMultiple, testSpikesLoader, testBgLoader)\n",
    "\n",
    "        testlabel = np.concatenate(([1 for _ in range(0,len(testSpikesLoader.dataset))],[0 for _ in range(0,len(testBgLoader.dataset))]),axis=0)\n",
    "\n",
    "        truepos = 0\n",
    "        falsepos = 0\n",
    "        trueneg = 0\n",
    "        falseneg = 0\n",
    "\n",
    "        for i in range(0, len(testlabel)):\n",
    "            if testlabel[i] == 1:\n",
    "                if testPredictions[i] == 1:\n",
    "                    truepos += 1\n",
    "                else:\n",
    "                    falseneg += 1\n",
    "            else:\n",
    "                if testPredictions[i] == 1:\n",
    "                    falsepos += 1\n",
    "                else:\n",
    "                    trueneg += 1\n",
    "\n",
    "        precision = truepos / (truepos + falsepos)\n",
    "        recall = truepos / (truepos + falseneg)  \n",
    "        f1 = 2 * ((precision * recall)/(precision+recall))\n",
    "        acc = (truepos + trueneg) / len(testlabel)\n",
    "        spec = trueneg / (falsepos + trueneg)\n",
    "\n",
    "        print(\"Precision: {}\".format(precision))\n",
    "        print(\"Recall: {}\".format(recall))\n",
    "        print(\"Specificity: {}\".format(spec))\n",
    "        print(\"F1: {}\".format(f1))\n",
    "        print(\"Accuracy: {}\".format(acc))\n",
    "\n",
    "        accDict[sdMultiple].append(acc)\n",
    "        precisionDict[sdMultiple].append(precision)\n",
    "        recallDict[sdMultiple].append(recall)\n",
    "        f1Dict[sdMultiple].append(f1)\n",
    "        specDict[sdMultiple].append(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr = [6.0, 5.5, 5.0, 4.5, 4.0, 3.5, 3.0, 2.5, 2.0, 1.5, 1.0, 0.5]\n",
    "plt.rcParams['figure.figsize'] = [16, 16]\n",
    "\n",
    "#plt.plot(np.sort(scale))\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(2,2)\n",
    "\n",
    "axs[0][0].title.set_text(\"Accuracy (0.5 SNR Step)\")\n",
    "axs[0][1].title.set_text(\"Specificity (0.5 SNR Step)\")\n",
    "axs[1][0].title.set_text(\"Sensitivity (0.5 SNR Step)\")\n",
    "axs[1][1].title.set_text(\"F1 (0.5 SNR Step)\")\n",
    "axs[0][0].set_xlabel(\"SNR\")\n",
    "axs[0][1].set_xlabel(\"SNR\")\n",
    "axs[1][0].set_xlabel(\"SNR\")\n",
    "axs[1][1].set_xlabel(\"SNR\")\n",
    "axs[0][0].set_ylabel(\"Accuracy\")\n",
    "axs[0][1].set_ylabel(\"Specificity\")\n",
    "axs[1][0].set_ylabel(\"Sensitivity\")\n",
    "axs[1][1].set_ylabel(\"F1\")\n",
    "\n",
    "axs[0][0].plot(snr, allAccuracy, label=\"Our Method\", marker='o')\n",
    "axs[0][1].plot(snr, allSpecificity, label=\"Our Method\", marker='o')\n",
    "axs[1][0].plot(snr, allRecall, label=\"Our Method\", marker='o')\n",
    "axs[1][1].plot(snr, allF1, label=\"Our Method\", marker='o')\n",
    "\n",
    "for x in multiplesOfSd:\n",
    "    axs[0][0].plot(snr, accDict[x], label=f\"threshold with {x} * sd\", marker='o')\n",
    "    axs[0][1].plot(snr, specDict[x], label=f\"threshold with {x} * sd\", marker='o')\n",
    "    axs[1][0].plot(snr, recallDict[x], label=f\"threshold with {x} * sd\", marker='o')\n",
    "    axs[1][1].plot(snr, f1Dict[x], label=f\"threshold with {x} * sd\", marker='o')\n",
    "    \n",
    "axs[0][0].legend()\n",
    "axs[0][1].legend()\n",
    "axs[1][0].legend()\n",
    "axs[1][1].legend()\n",
    "\n",
    "axs[0][0].set_ylim([0.5,1])\n",
    "axs[0][1].set_ylim([0,1])\n",
    "axs[1][0].set_ylim([0,1])\n",
    "axs[1][1].set_ylim([0,1])\n",
    "axs[0][0].invert_xaxis()\n",
    "axs[0][1].invert_xaxis()\n",
    "axs[1][0].invert_xaxis()\n",
    "axs[1][1].invert_xaxis()\n",
    "\n",
    "plt.show()\n",
    "plt.rcParams['figure.figsize'] = [16, 8]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy\")\n",
    "print(accDict)\n",
    "print(\"Precision\")\n",
    "print(precisionDict)\n",
    "print(\"Recall\")\n",
    "print(recallDict)\n",
    "print(\"Specificity\")\n",
    "print(specDict)\n",
    "print(\"F1\")\n",
    "print(f1Dict)\n",
    "print(\"snrs\")\n",
    "print([x/2 for x in range(12,0,-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# separates the spike samples\n",
    "\n",
    "(cleanextractedSpikesValidationSpikes,cleanextractedNoisesValidationSpikes) = sourceSeparation.maxlikelihood_separatesources(\n",
    "    generators=[gen1, gen2],\n",
    "    loader_mix=valSpikesLoader,\n",
    "    epochs=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# separates the noise samples\n",
    "\n",
    "(cleanextractedSpikesValidationBg,cleanextractedNoisesValidationBg) = sourceSeparation.maxlikelihood_separatesources(\n",
    "    generators=[gen1, gen2],\n",
    "    loader_mix=valBgLoader,\n",
    "    epochs=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valExtractedSpikes = np.concatenate((cleanextractedSpikesValidationSpikes,cleanextractedSpikesValidationBg),axis=0)\n",
    "vallabel = np.concatenate(([1 for _ in cleanextractedSpikesValidationSpikes],[0 for _ in cleanextractedSpikesValidationBg]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sourceSeparation.interpretSeparation(valExtractedSpikes, critic1, vallabel,method=\"critic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sourceSeparation.interpretSeparation(valExtractedSpikes, critic1, vallabel,method=\"energy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# separates the spike samples\n",
    "\n",
    "(cleanextractedSpikesTestSpikes,cleanextractedNoisesTestSpikes) = sourceSeparation.maxlikelihood_separatesources(\n",
    "    generators=[gen1, gen2],\n",
    "    loader_mix=testSpikesLoader,\n",
    "    epochs=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# separates the noise samples\n",
    "\n",
    "(cleanextractedSpikesTestBg,cleanextractedNoisesTestBg) = sourceSeparation.maxlikelihood_separatesources(\n",
    "    generators=[gen1, gen2],\n",
    "    loader_mix=testBgLoader,\n",
    "    epochs=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testExtractedSpikes = np.concatenate((cleanextractedSpikesTestSpikes,cleanextractedSpikesTestBg),axis=0)\n",
    "testlabel = np.concatenate(([1 for _ in cleanextractedSpikesTestSpikes],[0 for _ in cleanextractedSpikesTestBg]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sourceSeparation.interpretSeparation(testExtractedSpikes, critic1, testlabel,test=True, testThreshold=-21.5,method=\"critic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sourceSeparation.interpretSeparation(testExtractedSpikes, critic1, testlabel,test=True, testThreshold=0.35,method=\"energy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
